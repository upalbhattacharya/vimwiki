# Natural Language Processing


* [Neural Machine Translation by Jointly Learning to Align and Translate, 2014](attention)
* [Attention Is All You Need, 2017](transformers)
* [word2vec, doc2vec](embeddings)
* [node2vec: Scalable Feature Learning for Networks, 2016](node2vec) 
* [Deep contextualized word representation, 2018](elmo)
* [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, 2018](bert)
* [Improving Language Understanding by Generative Pre-Training, 2018](gpt1)
* [Doctor2Vec: Dynamic Representation Learning for Clinical Trial Recruitment, 2020](doctor2vec)

